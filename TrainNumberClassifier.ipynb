{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.133      -0.18990384  0.5054196   1.          0.2       ]\n",
      "[-0.118      -0.20552884  0.4968969   0.          0.2       ]\n",
      "[-0.1075     -0.01051683  0.50130117  0.          0.2       ]\n",
      "[-0.019       0.27103364  0.20217966  0.          0.5       ]\n",
      "[ 0.00475    -0.38371393  0.05388929  0.          0.7       ]\n",
      "[ 0.02825    -0.14903846  0.24669164  0.          0.9       ]\n",
      "[0.         0.         0.04632778 0.         0.5       ]\n",
      "[1.7999999e-02 3.4945914e-01 2.4812930e-04 0.0000000e+00 3.0000001e-01]\n",
      "[ 0.06175    -0.30438703  0.5613011   0.          0.5       ]\n",
      "[0.111      0.09405048 0.25306743 1.         0.5       ]\n",
      "[0.0915     0.47866586 0.49958566 0.         0.2       ]\n",
      "[ 1.3225000e-01 -6.0096155e-03  2.2073409e-04  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.11725    -0.38852164  0.48813513  0.          0.2       ]\n",
      "[-0.20675    -0.3846154   0.51701677  0.          0.8       ]\n",
      "[ 0.206      -0.15204327  0.1163181   0.          0.3       ]\n",
      "[-2.1325000e-01 -5.1081730e-03  1.7014128e-04  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[-0.1455      0.47926682  0.38376096  0.          0.2       ]\n",
      "[ 0.0125     -0.18960336  0.21301776  0.          0.7       ]\n",
      "[0.00075    0.27584136 0.06839553 0.         0.6       ]\n",
      "[0.         0.         0.01164749 0.         0.5       ]\n",
      "[-0.00175    -0.37770432  0.1336079   0.          0.4       ]\n",
      "[-0.0215      0.3608774   0.29197165  0.          0.2       ]\n",
      "[ 0.05025    -0.11147837  0.6961846   0.          0.6       ]\n",
      "[ 0.037      -0.2794471   0.00197131  0.          0.4       ]\n",
      "[-0.00225     0.09765625  0.58285666  1.          0.5       ]\n",
      "[0.0275     0.35246393 0.02660004 0.         0.6       ]\n",
      "[0.         0.         0.48187682 0.         0.2       ]\n",
      "[6.5750003e-02 1.5024039e-03 4.6641828e-05 0.0000000e+00 3.0000001e-01]\n",
      "[0.14325    0.48527643 0.45266175 0.         0.2       ]\n",
      "[ 0.29025   -0.4627404  0.4994776  0.         0.2      ]\n",
      "[-0.0205      0.2721598   0.20015348  0.          0.5       ]\n",
      "[ 0.02925    -0.1488764   0.30461842  0.          0.9       ]\n",
      "[ 0.00625    -0.3823346   0.10735653  0.          0.7       ]\n",
      "[0.         0.         0.00784933 0.         0.5       ]\n",
      "[0.0235     0.3417603  0.00828534 0.         0.3       ]\n",
      "[ 0.06975    -0.31117353  0.6879016   0.          0.5       ]\n",
      "[0.04475    0.47971287 0.00085124 0.         0.2       ]\n",
      "[0.09725    0.08614232 0.58321637 1.         0.5       ]\n",
      "[ 0.1285     -0.00842697  0.00051212  0.          0.3       ]\n",
      "[ 0.11475    -0.38982522  0.02452496  0.          0.2       ]\n",
      "[ 1.9675000e-01 -1.5667915e-01  4.8877030e-07  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[-0.19925    -0.38077402  0.50778866  0.          0.8       ]\n",
      "[0.216      0.47908863 0.3472147  0.         0.2       ]\n",
      "[-0.206      -0.00124844  0.00045293  0.          0.3       ]\n",
      "[-0.03125     0.335206    0.06699392  1.          0.7       ]\n",
      "[ 0.01175    -0.19069913  0.16266522  0.          0.7       ]\n",
      "[0.         0.27652934 0.35733795 1.         0.6       ]\n",
      "[0.         0.         0.00633759 0.         0.5       ]\n",
      "[-0.00475    -0.12484395  0.8497766   0.          0.3       ]\n",
      "[-0.0025     -0.3770287   0.23707189  0.          0.4       ]\n",
      "[ 0.0295     -0.30836454  0.14510058  0.          0.4       ]\n",
      "[-0.01725     0.10143571  0.2697497   1.          0.5       ]\n",
      "[ 0.03275    -0.11922596  0.366018    0.          0.2       ]\n",
      "[0.         0.         0.49351683 0.         0.2       ]\n",
      "[ 0.05475    -0.3258427   0.11607191  1.          0.2       ]\n",
      "[6.4499997e-02 6.2421971e-04 2.9579288e-04 0.0000000e+00 3.0000001e-01]\n",
      "[0.07675    0.49219725 0.0362036  0.         0.2       ]\n",
      "[ 0.1245     -0.2977528   0.51181036  0.          0.2       ]\n",
      "[-0.0135      0.26862982  0.20651594  0.          0.5       ]\n",
      "[-0.00425    -0.38070914  0.12672332  0.          0.7       ]\n",
      "[ 0.02625    -0.14783654  0.3508228   0.          0.9       ]\n",
      "[0.         0.         0.01943022 0.         0.5       ]\n",
      "[ 0.06375    -0.30949518  0.5842111   0.          0.5       ]\n",
      "[-0.19625    -0.13371395  0.00694752  0.          0.3       ]\n",
      "[0.10225    0.08533654 0.5234871  1.         0.5       ]\n",
      "[ 0.10775    -0.38852164  0.01631598  0.          0.2       ]\n",
      "[ 1.3150001e-01 -8.4134620e-03  1.5806045e-05  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.199      -0.14993991  0.33323023  0.          0.3       ]\n",
      "[ 0.22025    -0.38701922  0.6339813   0.          0.8       ]\n",
      "[0.         0.         0.00923798 0.         0.2       ]\n",
      "[ 0.22225    -0.00961538  0.00398604  0.          0.3       ]\n",
      "[ 0.4405     -0.19801682  0.1610408   0.          0.7       ]\n",
      "[ 0.42175    -0.38311297  0.21458933  0.          0.4       ]\n",
      "[ 4.1249999e-01 -8.7139420e-03  2.1890246e-06  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[0.19625    0.0015024  0.50000036 1.         0.2       ]\n",
      "[ 0.20875    -0.20522836  0.20545764  0.          0.6       ]\n",
      "[ 0.4255     -0.13221154  0.8868288   0.          0.3       ]\n",
      "[ 0.45725    -0.31460336  0.24253884  0.          0.4       ]\n",
      "[ 0.28975    -0.38371393  0.25717363  1.          0.5       ]\n",
      "[ 0.46275    -0.01201923  0.02635447  1.          0.2       ]\n",
      "[ 0.34075    -0.14332932  0.02525324  0.          0.5       ]\n",
      "[ 0.566      -0.13100961  0.37511143  0.          0.2       ]\n",
      "[ 0.3095     -0.48227164  0.9487177   0.          0.2       ]\n",
      "[ 0.58475    -0.3374399   0.02801955  1.          0.2       ]\n",
      "[ 3.7125000e-01 -4.8347357e-01  2.0872065e-04  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.65675    -0.30859375  0.50988424  0.          0.2       ]\n",
      "[0.58075    0.00360577 0.30409068 1.         0.3       ]\n",
      "[-0.10425    0.1754386  0.4955402  0.         0.2      ]\n",
      "[ 0.0205     -0.29678363  0.43095145  0.          0.6       ]\n",
      "[-0.01875     0.27046785  0.19986704  0.          0.5       ]\n",
      "[ 0.00075    -0.38157895  0.03986497  0.          0.7       ]\n",
      "[ 0.02875    -0.14736842  0.3915195   0.          0.9       ]\n",
      "[-0.0185      0.4730994   0.01142034  0.          0.2       ]\n",
      "[0.000000e+00 0.000000e+00 4.970935e-04 0.000000e+00 5.000000e-01]\n",
      "[0.0285     0.33918127 0.00077035 0.         0.3       ]\n",
      "[0.124      0.09122807 0.49816427 1.         0.4       ]\n",
      "[ 1.3575000e-01 -6.7251460e-03  5.0545697e-07  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.116      -0.3880117   0.49517375  0.          0.2       ]\n",
      "[ 2.1950001e-01 -1.5350877e-01  1.3452184e-05  0.0000000e+00\n",
      "  2.0000000e-01]\n",
      "[-0.21475    -0.38099414  0.60286075  0.          0.8       ]\n",
      "[-2.1699999e-01 -1.7543860e-03  1.5419813e-04  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.01       -0.18976608  0.2704355   0.          0.7       ]\n",
      "[0.00125    0.2739766  0.08410899 0.         0.6       ]\n",
      "[0.        0.        0.0005015 0.        0.5      ]\n",
      "[-0.007      -0.3766082   0.21676257  0.          0.4       ]\n",
      "[-0.0035     -0.12397661  0.83904034  0.          0.3       ]\n",
      "[-0.04025   -0.3026316  0.3282365  1.         0.6      ]\n",
      "[-0.0205      0.09678362  0.04416097  1.          0.4       ]\n",
      "[0.03075    0.34327486 0.0576626  0.         0.5       ]\n",
      "[ 0.03375    -0.11783626  0.36549798  0.          0.3       ]\n",
      "[0.         0.         0.00177306 0.         0.2       ]\n",
      "[0.03575    0.48391813 0.19797489 0.         0.2       ]\n",
      "[0.067      0.00116959 0.26842043 0.         0.3       ]\n",
      "[ 0.12775    -0.29590642  0.512893    0.          0.2       ]\n",
      "[0.2665     0.4853801  0.19432981 1.         0.4       ]\n",
      "[ 0.29625    -0.09385965  0.03888547  0.          0.2       ]\n",
      "[0.16875    0.4674574  0.03844108 1.         0.3       ]\n",
      "[-0.0185      0.27037713  0.21770069  0.          0.5       ]\n",
      "[ 0.028      -0.14872263  0.2835787   0.          0.9       ]\n",
      "[ 0.00375    -0.38716546  0.22386143  1.          0.7       ]\n",
      "[0.         0.         0.00869336 0.         0.5       ]\n",
      "[ 0.06075    -0.30930656  0.38941276  0.          0.5       ]\n",
      "[0.0495     0.33515814 0.00404996 0.         0.3       ]\n",
      "[0.122      0.08667883 0.4001307  1.         0.5       ]\n",
      "[ 0.12925    -0.00608273  0.00050369  0.          0.3       ]\n",
      "[ 0.11525    -0.38777372  0.00973755  0.          0.2       ]\n",
      "[ 1.9200000e-01 -1.4993918e-01  2.9953944e-05  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.2255     -0.38381994  0.6247229   0.          0.8       ]\n",
      "[ 0.219      -0.00425791  0.08436517  0.          0.3       ]\n",
      "[-0.10375    -0.1140511   0.65037054  0.          0.3       ]\n",
      "[-0.09225    -0.18643552  0.20092578  0.          0.7       ]\n",
      "[-0.00475     0.3397202   0.10885093  1.          0.6       ]\n",
      "[-0.103       0.27950123  0.28366822  0.          0.6       ]\n",
      "[-0.1035      0.00273723  0.00174594  0.          0.5       ]\n",
      "[-6.7749999e-02 -3.0139902e-01  2.4843751e-04  0.0000000e+00\n",
      "  4.0000001e-01]\n",
      "[-0.1065    -0.3759124  0.2512012  0.         0.4      ]\n",
      "[-0.007       0.10097323  0.8736307   0.          0.5       ]\n",
      "[0.         0.         0.49360842 0.         0.2       ]\n",
      "[ 0.07175    -0.11283455  0.3226179   0.          0.3       ]\n",
      "[0.06525    0.0033455  0.10897432 0.         0.3       ]\n",
      "[ 0.108      -0.30413625  0.5436143   0.          0.3       ]\n",
      "[ 0.2015     -0.2910584   0.54925346  0.          0.2       ]\n",
      "[0.28075    0.37682483 0.4759266  0.         0.2       ]\n",
      "[0.27175    0.44951338 0.06476166 0.         0.2       ]\n",
      "[ 0.2675     -0.17487834  0.26277605  1.          0.2       ]\n",
      "[ 0.2685     -0.12956205  0.87794536  1.          0.2       ]\n",
      "[-0.08625    -0.46932322  0.00129666  0.          0.2       ]\n",
      "[-1.4174999e-01 -4.3137255e-01  1.3070746e-07  0.0000000e+00\n",
      "  2.0000000e-01]\n",
      "[-0.09275     0.14737508  0.33869606  1.          0.3       ]\n",
      "[-0.09325     0.12175838  0.5002724   1.          0.2       ]\n",
      "[-0.0935      0.26154333  0.4904501   0.          0.2       ]\n",
      "[-0.09275     0.16761543  0.47178322  0.          0.2       ]\n",
      "[-0.093       0.13029727  0.35009825  0.          0.2       ]\n",
      "[-0.077       0.48450348  0.16488835  0.          0.2       ]\n",
      "[-0.08875     0.1195446   0.05774371  0.          0.2       ]\n",
      "[-0.012       0.26691967  0.20002064  0.          0.5       ]\n",
      "[-0.00575    -0.38298544  0.14624058  0.          0.7       ]\n",
      "[ 0.023      -0.1486401   0.41931984  0.          0.9       ]\n",
      "[0.         0.         0.00493576 0.         0.5       ]\n",
      "[0.061      0.10246679 0.3786064  1.         0.6       ]\n",
      "[2.9999999e-02 3.3459836e-01 1.6672051e-04 1.0000000e+00 2.0000000e-01]\n",
      "[-0.03475   -0.2836812  0.3581363  1.         0.5      ]\n",
      "[0.158      0.47122073 0.1876296  1.         0.9       ]\n",
      "[-0.02525    -0.38235295  0.05422722  0.          0.2       ]\n",
      "[0.        0.        0.2356251 0.        0.4      ]\n",
      "[ 4.550000e-02 -9.266287e-02  6.737056e-07  0.000000e+00  3.000000e-01]\n",
      "[ 0.08325   -0.3791904  0.5476632  0.         0.8      ]\n",
      "[0.087      0.00189753 0.13652135 0.         0.4       ]\n",
      "[-0.1545      0.4452878   0.00700559  0.          0.2       ]\n",
      "[-0.09175    -0.18469323  0.1684306   1.          0.7       ]\n",
      "[-0.0595    -0.285895   0.3895328  0.         0.5      ]\n",
      "[-0.10975    -0.37254903  0.25892046  0.          0.4       ]\n",
      "[-0.096      -0.09424415  0.6672116   0.          0.3       ]\n",
      "[-0.0945      0.2738773   0.16743018  1.          0.6       ]\n",
      "[-0.1         0.00379507  0.03348961  0.          0.6       ]\n",
      "[-0.12975     0.50126505  0.4987917   0.          0.2       ]\n",
      "[-0.12975     0.49652117  0.12593144  0.          0.2       ]\n",
      "[-0.0195      0.13345984  0.60484624  1.          0.6       ]\n",
      "[0.0065     0.34598356 0.0225529  1.         0.7       ]\n",
      "[0.         0.         0.00264213 0.         0.2       ]\n",
      "[0.1385     0.44845036 0.14974613 1.         0.6       ]\n",
      "[ 0.06925  -0.100253  0.495355  0.        0.3     ]\n",
      "[6.1999999e-02 3.1625552e-04 1.7082364e-04 0.0000000e+00 4.0000001e-01]\n",
      "[ 0.14575    -0.28779253  0.25042847  0.          0.4       ]\n",
      "[0.1        0.49841872 0.49820164 0.         0.2       ]\n",
      "[ 0.29325    -0.2836812   0.16677761  1.          0.2       ]\n",
      "[ 0.3065     -0.19323213  0.04423782  1.          0.2       ]\n",
      "[ 0.30675    -0.3633776   0.38075575  1.          0.2       ]\n",
      "[0.30275    0.01296648 0.10426831 1.         0.2       ]\n",
      "[ 0.30575    -0.01391524  0.00202178  0.          0.2       ]\n",
      "[3.1900001e-01 3.0075902e-01 6.7077408e-06 1.0000000e+00 3.0000001e-01]\n",
      "[ 0.3195     -0.30328906  0.6488918   0.          0.2       ]\n",
      "[ 3.1825000e-01 -4.0480707e-02  4.3748390e-05  0.0000000e+00\n",
      "  2.0000000e-01]\n",
      "[0.3205     0.23940544 0.00209383 1.         0.2       ]\n",
      "[-0.14225    -0.49622643  0.6498969   0.          0.3       ]\n",
      "[-0.12225    -0.46289307  0.09218647  0.          0.2       ]\n",
      "[-0.074       0.41792452  0.25869796  1.          0.4       ]\n",
      "[-0.0065     -0.38018867  0.00178858  0.          0.7       ]\n",
      "[-0.011       0.26981133  0.20079717  0.          0.5       ]\n",
      "[ 0.02275    -0.1481132   0.43211108  0.          0.9       ]\n",
      "[0.         0.         0.00065558 0.         0.5       ]\n",
      "[-0.042       0.11572327  0.6688588   1.          0.6       ]\n",
      "[-0.03525    -0.28207546  0.4410376   0.          0.5       ]\n",
      "[0.03075    0.33867925 0.00126591 0.         0.2       ]\n",
      "[-0.026      -0.3798742   0.01268256  0.          0.2       ]\n",
      "[0.        0.        0.2419095 0.        0.4      ]\n",
      "[-0.01675    -0.46352202  0.00094891  0.          0.2       ]\n",
      "[ 0.0235     -0.08647799  0.01307929  1.          0.3       ]\n",
      "[ 0.00725    -0.46981132  0.24644484  0.          0.2       ]\n",
      "[ 0.08      -0.3773585  0.7023845  0.         0.8      ]\n",
      "[7.0000000e-02 4.7735849e-01 7.6305063e-04 1.0000000e+00 3.0000001e-01]\n",
      "[0.07275   0.4572327 0.2379258 1.        0.3      ]\n",
      "[0.08625    0.00157233 0.0007525  0.         0.3       ]\n",
      "[-0.0925     -0.18396227  0.16332701  1.          0.7       ]\n",
      "[-0.062      -0.28396225  0.39692587  0.          0.5       ]\n",
      "[-0.10725    -0.09119496  0.5415913   0.          0.3       ]\n",
      "[-0.11225    -0.36949685  0.20718186  0.          0.4       ]\n",
      "[-0.09825     0.00440252  0.12012766  0.          0.6       ]\n",
      "[-0.0895      0.27704403  0.42700884  0.          0.6       ]\n",
      "[0.01175    0.35062894 0.0104121  1.         0.6       ]\n",
      "[-0.008      0.1172956  0.3687505  1.         0.6      ]\n",
      "[0.         0.         0.00094263 0.         0.2       ]\n",
      "[ 0.0455     -0.09968553  0.3370036   0.          0.3       ]\n",
      "[0.0615     0.00062893 0.00040942 0.         0.4       ]\n",
      "[ 0.1395     -0.28584906  0.2539211   0.          0.4       ]\n",
      "[ 0.32025    -0.4427673   0.23689133  0.          0.2       ]\n",
      "[ 0.3065     -0.11069182  0.04143258  0.          0.2       ]\n",
      "[-0.0265      0.2674951   0.37615648  0.          0.5       ]\n",
      "[0.0000000e+00 0.0000000e+00 1.9523574e-04 0.0000000e+00 5.0000000e-01]\n",
      "[ 0.03025    -0.14519294  0.22827928  0.          0.9       ]\n",
      "[ 0.0185     -0.2907129   0.52578807  0.          0.5       ]\n",
      "[0.04075    0.11641596 0.68693876 1.         0.5       ]\n",
      "[ 0.0155     -0.37115762  0.00085277  0.          0.7       ]\n",
      "[2.0000000e-02 3.4074560e-01 1.8908532e-04 0.0000000e+00 2.0000000e-01]\n",
      "[-0.0125     -0.27501634  0.03149526  0.          0.4       ]\n",
      "[0.        0.        0.2478467 0.        0.4      ]\n",
      "[-0.00575   -0.3705036  0.3796219  0.         0.2      ]\n",
      "[ 7.69999996e-02 -1.03989534e-01  1.16362182e-08  0.00000000e+00\n",
      "  3.00000012e-01]\n",
      "[ 0.098      -0.36821452  0.6968414   0.          0.8       ]\n",
      "[0.085      0.00098103 0.10918576 0.         0.4       ]\n",
      "[-1.687500e-01  4.679529e-01  7.258528e-04  1.000000e+00  2.000000e-01]\n",
      "[ 0.126     -0.0412034  0.4082212  0.         0.2      ]\n",
      "[-0.1015      0.27305427  0.19128282  1.          0.6       ]\n",
      "[-0.08325    -0.18018313  0.154844    1.          0.7       ]\n",
      "[-0.09725     0.00359712  0.00548238  0.          0.6       ]\n",
      "[-0.04825    -0.26618704  0.01103078  0.          0.4       ]\n",
      "[-0.124      -0.03695226  0.2045114   0.          0.2       ]\n",
      "[-0.094      -0.36069328  0.2154693   0.          0.4       ]\n",
      "[-0.0795     -0.09679529  0.30134827  0.          0.3       ]\n",
      "[-0.022       0.12099411  0.5614701   1.          0.5       ]\n",
      "[0.02925    0.34466973 0.0006995  0.         0.3       ]\n",
      "[0.         0.         0.00261585 0.         0.2       ]\n",
      "[ 0.01775    -0.03564421  0.00151982  0.          0.3       ]\n",
      "[ 0.09075    -0.10170045  0.09183022  0.          0.3       ]\n",
      "[0.0605     0.00065402 0.22706202 0.         0.4       ]\n",
      "[0.08875    0.48332244 0.17169976 0.         0.2       ]\n",
      "[8.6999997e-02 4.6272072e-01 3.3823429e-07 0.0000000e+00 2.0000000e-01]\n",
      "[ 0.14775    -0.2792675   0.13101377  0.          0.4       ]\n",
      "[0.12725   0.4620667 0.0051317 0.        0.2      ]\n",
      "[0.24325    0.14617397 0.49188066 0.         0.2       ]\n",
      "[-0.015       0.28087887  0.20372078  0.          0.5       ]\n",
      "[-0.00325    -0.39162707  0.14142211  0.          0.7       ]\n",
      "[ 0.02725    -0.15201901  0.38381135  0.          0.9       ]\n",
      "[0.         0.         0.01375932 0.         0.5       ]\n",
      "[ 0.08575    -0.31591448  0.28952977  0.          0.6       ]\n",
      "[0.02475    0.35985747 0.00435936 0.         0.3       ]\n",
      "[0.0855     0.10896675 0.34956092 1.         0.5       ]\n",
      "[ 0.1145     -0.40320665  0.09340127  0.          0.2       ]\n",
      "[ 0.1395     -0.01098575  0.00246686  0.          0.3       ]\n",
      "[ 2.0200001e-01 -1.5350357e-01  1.9924972e-05  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.2325    -0.4070665  0.5068963  0.         0.8      ]\n",
      "[ 2.3549999e-01 -1.6033255e-02  5.6849814e-05  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[-0.1005     -0.18289787  0.24987629  1.          0.7       ]\n",
      "[-0.1205    -0.375      0.5766444  0.         0.4      ]\n",
      "[-0.10225     0.29750594  0.08582785  1.          0.6       ]\n",
      "[-1.28999993e-01  1.39548695e-02  1.33978974e-04  0.00000000e+00\n",
      "  3.00000012e-01]\n",
      "[-0.077      -0.28473872  0.00120227  1.          0.4       ]\n",
      "[-0.08475    -0.10184085  0.17248657  0.          0.2       ]\n",
      "[-5.0000002e-04  1.2796912e-01  4.9138409e-01  1.0000000e+00\n",
      "  5.0000000e-01]\n",
      "[-0.07875     0.00801663  0.24826427  1.          0.2       ]\n",
      "[0.03875    0.36638954 0.1040827  0.         0.5       ]\n",
      "[0.0000000e+00 0.0000000e+00 4.3896816e-07 0.0000000e+00 2.0000000e-01]\n",
      "[0.005      0.01098575 0.879955   0.         0.2       ]\n",
      "[ 0.033      -0.11163896  0.499783    0.          0.2       ]\n",
      "[0.0695     0.00326603 0.26473165 0.         0.4       ]\n",
      "[ 0.29025    -0.36965558  0.43528315  0.          0.2       ]\n",
      "[0.152     0.4721875 0.6356672 1.        0.5      ]\n",
      "[-0.1425    -0.096875   0.5299455  0.         0.2      ]\n",
      "[-0.1305     -0.0890625   0.93999815  0.          0.2       ]\n",
      "[-0.01325     0.270625    0.40483695  0.          0.4       ]\n",
      "[ 0.02875    -0.1459375   0.30474052  0.          0.9       ]\n",
      "[0.         0.         0.02600462 0.         0.5       ]\n",
      "[ 0.01025    -0.375625    0.22550164  0.          0.7       ]\n",
      "[0.06575    0.1003125  0.05561871 1.         0.3       ]\n",
      "[0.042     0.3384375 0.4964907 0.        0.4      ]\n",
      "[ 0.08875    -0.3075      0.11763876  0.          0.5       ]\n",
      "[ 1.2825000e-01 -9.0624997e-03  1.0575491e-04  0.0000000e+00\n",
      "  3.0000001e-01]\n",
      "[ 0.1185     -0.384375    0.00108565  0.          0.2       ]\n",
      "[ 0.18375    -0.1509375   0.18979362  0.          0.3       ]\n",
      "[-0.198     -0.3765625  0.6622793  0.         0.8      ]\n",
      "[-0.208      -0.0015625   0.06975153  0.          0.3       ]\n",
      "[-0.0045     0.2740625  0.2885746  0.         0.6      ]\n",
      "[ 0.01275    -0.1875      0.32556263  0.          0.7       ]\n",
      "[0.         0.         0.21121308 0.         0.5       ]\n",
      "[-0.001      -0.3721875   0.22500212  0.          0.4       ]\n",
      "[ 0.02375   -0.1246875  0.1336917  0.         0.2      ]\n",
      "[0.02575   0.3325    0.1804163 1.        0.9      ]\n",
      "[ 0.031     -0.2996875  0.3312639  0.         0.3      ]\n",
      "[-0.00525     0.1075      0.48194897  1.          0.4       ]\n",
      "[0.         0.         0.03998747 0.         0.2       ]\n",
      "[ 0.05775    -0.3028125   0.64275575  0.          0.3       ]\n",
      "[0.065      0.         0.03763582 1.         0.3       ]\n",
      "[ 0.12925    -0.3         0.01447242  0.          0.2       ]\n",
      "[0.20075    0.4828125  0.02509604 1.         0.2       ]\n",
      "[0.2755     0.2365625  0.49651453 0.         0.2       ]\n",
      "[0.27675    0.1709375  0.49999782 1.         0.2       ]\n",
      "[0.27325    0.32125    0.49565163 0.         0.2       ]\n",
      "[2.8299999e-01 1.2281250e-01 2.6876281e-05 0.0000000e+00 2.0000000e-01]\n",
      "[ 0.27525    -0.4675      0.41729146  0.          0.2       ]\n",
      "[ 0.28425    -0.39375     0.01403008  0.          0.2       ]\n",
      "[ 0.2965     -0.1290625   0.20560469  0.          0.2       ]\n",
      "[0.         0.19629899 0.17355804 0.         0.5       ]\n",
      "[0.         0.         0.00107712 0.         0.4       ]\n",
      "[-0.0095      0.40965167  0.07274692  0.          0.5       ]\n",
      "[0.024      0.48875183 0.20137756 1.         0.3       ]\n",
      "[0.08975    0.27648765 0.04879344 0.         0.3       ]\n",
      "[ 0.08725    -0.16618288  0.00122661  0.          0.2       ]\n",
      "[ 0.14775    -0.46952105  0.09197618  1.          0.3       ]\n",
      "[0.14775    0.0446299  0.35212293 1.         0.3       ]\n",
      "[-1.4675000e-01 -3.3490565e-01  4.9769751e-06  0.0000000e+00\n",
      "  4.0000001e-01]\n",
      "[-0.09675    -0.2565312   0.67845887  0.          0.8       ]\n",
      "[-1.5975000e-01 -1.4296082e-01  4.8846719e-06  0.0000000e+00\n",
      "  2.0000000e-01]\n",
      "[ 0.01925    -0.13969521  0.3336524   0.          0.3       ]\n",
      "[0.         0.         0.01782319 0.         0.2       ]\n",
      "[ 0.0545    -0.3417997  0.3720566  0.         0.4      ]\n",
      "[2.3499999e-02 2.0682149e-01 3.9568854e-06 0.0000000e+00 4.0000001e-01]\n",
      "[0.04625   0.4179971 0.0189202 0.        0.5      ]\n",
      "[0.08775    0.282656   0.05107732 0.         0.5       ]\n",
      "[0.05525    0.51197386 0.33327967 0.         0.3       ]\n",
      "[0.125      0.07801161 0.39149103 1.         0.4       ]\n",
      "[1.7174999e-01 5.1378810e-01 2.2862896e-09 0.0000000e+00 2.0000000e-01]\n",
      "[0.25125    0.28846154 0.00235084 0.         0.3       ]\n",
      "[ 0.357      -0.43396226  0.01133082  0.          0.3       ]\n",
      "[ 0.352      -0.30696663  0.4882125   1.          0.2       ]\n",
      "[0.39275    0.02685051 0.15455651 0.         0.2       ]\n",
      "[0.3965     0.32438317 0.49033317 0.         0.2       ]\n",
      "[ 0.45975    -0.4357765   0.56059635  1.          0.5       ]\n",
      "[-0.44025     0.2767857   0.20029707  0.          0.5       ]\n",
      "[-0.11        0.00646552  0.01610148  0.          0.7       ]\n",
      "[-0.08475     0.24014778  0.3044235   0.          0.9       ]\n",
      "[-0.10925     0.38947046  0.00091323  0.          0.4       ]\n",
      "[-1.1625000e-01 -8.7438427e-02  2.1842736e-05  0.0000000e+00\n",
      "  2.0000000e-01]\n",
      "[-0.33525     0.10160098  0.5074938   1.          0.4       ]\n",
      "[-0.0115      0.07389162  0.0037059   1.          0.5       ]\n",
      "[-0.341       0.33682266  0.00191555  0.          0.2       ]\n",
      "[-0.257      -0.00092365  0.02652843  0.          0.6       ]\n",
      "[0.         0.         0.00134312 0.         0.2       ]\n",
      "[8.275000e-02 2.515394e-01 2.979290e-05 0.000000e+00 3.000000e-01]\n",
      "[0.11       0.00215517 0.6695415  0.         0.8       ]\n",
      "[-0.0655      0.47937194  0.01723385  0.          0.2       ]\n",
      "[-0.0205     -0.18503694  0.2482946   0.          0.4       ]\n",
      "[0.005      0.27463055 0.16708714 0.         0.6       ]\n",
      "[0.         0.         0.01600457 0.         0.5       ]\n",
      "[-0.00675    -0.3746921   0.07581008  0.          0.4       ]\n",
      "[0.0935     0.34359607 0.05740282 1.         0.6       ]\n",
      "[ 0.056      -0.29495075  0.5020738   1.          0.4       ]\n",
      "[ 0.0745     -0.12192118  0.41618377  0.          0.6       ]\n",
      "[0.111      0.09913793 0.54480654 1.         0.5       ]\n",
      "[ 0.051      -0.19119458  0.00267818  0.          0.3       ]\n",
      "[ 0.1385     -0.00277094  0.02577263  0.          0.5       ]\n",
      "[ 0.22975    -0.2921798   0.47093654  0.          0.2       ]\n"
     ]
    }
   ],
   "source": [
    "#read in csv\n",
    "datasetPath = 'depth_train_dataset.csv'\n",
    "dataList = []\n",
    "labelList = []\n",
    "for i, row in enumerate(open(datasetPath)):\n",
    "    if i == 0: continue #skip first row, header rown\n",
    "    # parse the label and image from the row\n",
    "    row = row.split(\",\")\n",
    "    #print(row)\n",
    "    label = int(row[0])\n",
    "    datarow = np.array([x for x in row[1:6]], dtype=\"float32\")\n",
    "    \n",
    "    print(datarow)\n",
    "    \n",
    "    dataList.append(datarow)\n",
    "    labelList.append(label)\n",
    "data = np.array(dataList, dtype=\"float32\")\n",
    "labels = np.array(labelList, dtype=\"int\")\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=3) # 70% training and 30% test\n",
    "\n",
    "# Feature Scaling\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8928571428571429\n",
      "Precision: 0.4\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "#SVM linear model\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', class_weight='balanced', gamma='scale', random_state=112) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: # correctly predicted positives / # predicted as positive\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: # correctly predicted positives / # actual positives\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# F1 Score F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9285714285714286\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#SVM gaussian model\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf', class_weight='balanced', gamma='scale', random_state=8) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: # correctly predicted positives / # predicted as positive\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: # correctly predicted positives / # actual positives\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# F1 Score F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9732142857142857\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8421052631578948\n"
     ]
    }
   ],
   "source": [
    "#SVM Polynomial model\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='poly', degree=4, class_weight='balanced', gamma='scale', random_state=3) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: # correctly predicted positives / # predicted as positive\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: # correctly predicted positives / # actual positives\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# F1 Score F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7410714285714286\n",
      "Precision: 0.08\n",
      "Recall: 0.25\n",
      "F1 Score: 0.12121212121212122\n"
     ]
    }
   ],
   "source": [
    "#SVM sigmoid model\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='sigmoid', class_weight='balanced', gamma='scale', random_state=112) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: # correctly predicted positives / # predicted as positive\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: # correctly predicted positives / # actual positives\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# F1 Score F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9017857142857143\n",
      "Precision: 0.42105263157894735\n",
      "Recall: 1.0\n",
      "F1 Score: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "#logistic regression model\n",
    "#Create\n",
    "clf = linear_model.LogisticRegression(class_weight='balanced', random_state=None) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: # correctly predicted positives / # predicted as positive\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: # correctly predicted positives / # actual positives\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# F1 Score F1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\",metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0789046\n",
      "1.9235044\n",
      "[-1.1104561  -1.6329515  -0.66361654 -0.5371752 ]\n",
      "[ 0.43669268  0.06361189  1.8991386  -0.5371752 ]\n"
     ]
    }
   ],
   "source": [
    "#random forest model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 12]\n",
      " [ 0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       104\n",
      "           1       0.40      1.00      0.57         8\n",
      "\n",
      "    accuracy                           0.89       112\n",
      "   macro avg       0.70      0.94      0.76       112\n",
      "weighted avg       0.96      0.89      0.91       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '2f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-99247d03b19e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mall_sample_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Accuracy Score: {0.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_sample_title\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '2f'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0.2f}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
